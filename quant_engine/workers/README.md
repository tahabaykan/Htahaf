# Deeper Analysis Worker

## Overview

The Deeper Analysis Worker processes CPU/IO-heavy computations (GOD, ROD, GRPAN) in a **separate process** to avoid blocking the main FastAPI application. This allows you to:

- ‚úÖ Place orders while deeper analysis runs
- ‚úÖ Keep the main application responsive
- ‚úÖ Run multiple workers for load distribution
- ‚úÖ Scale horizontally as needed

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Frontend      ‚îÇ
‚îÇ   (React)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   FastAPI       ‚îÇ  ‚Üê Main Application (Terminal 1)
‚îÇ   (Port 8000)   ‚îÇ     - Handles orders
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     - Market data
         ‚îÇ              - WebSocket
         ‚îÇ POST /api/deeper-analysis/compute
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Redis       ‚îÇ  ‚Üê Message Broker (Docker)
‚îÇ   (Port 6379)   ‚îÇ     - Job Queue
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     - Results Cache
         ‚îÇ
         ‚îÇ BRPOP (blocking pop)
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Worker Process ‚îÇ  ‚Üê Separate Terminal (Terminal 2+)
‚îÇ  (Background)   ‚îÇ     - Processes jobs
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     - Computes GOD/ROD/GRPAN
```

## Quick Start

### 1. Start Redis (if not running)

Redis should auto-start with `baslat.py`, but if needed:

```bash
docker start redis-quant-engine
```

### 2. Start Main Application (Terminal 1)

```bash
cd quant_engine
python baslat.py
# Or: python main.py api
```

### 3. Start Worker (Terminal 2)

**Windows:**
```bash
cd quant_engine
workers\start_worker.bat
```

**Linux/Mac:**
```bash
cd quant_engine
chmod +x workers/start_worker.sh
./workers/start_worker.sh
```

**Or directly:**
```bash
python workers/run_deeper_worker.py
```

## Multi-Terminal Setup

### Recommended Setup (3-4 Terminals)

#### Terminal 1: Main FastAPI Application
```bash
cd quant_engine
python baslat.py
```
**Purpose:** Handles all API requests, WebSocket, order placement

#### Terminal 2: Deeper Analysis Worker #1
```bash
cd quant_engine
set WORKER_NAME=worker1
workers\start_worker.bat
```
**Purpose:** Processes deeper analysis jobs

#### Terminal 3: Deeper Analysis Worker #2 (Optional)
```bash
cd quant_engine
set WORKER_NAME=worker2
workers\start_worker.bat
```
**Purpose:** Additional worker for load distribution

#### Terminal 4: Redis Monitor (Optional)
```bash
docker exec -it redis-quant-engine redis-cli
# Then: MONITOR
```
**Purpose:** Monitor Redis activity

### Environment Variables

You can customize worker behavior:

```bash
# Windows
set WORKER_NAME=worker1
set POLL_TIMEOUT=5
set MAX_JOB_TIME=300
python workers\run_deeper_worker.py

# Linux/Mac
export WORKER_NAME=worker1
export POLL_TIMEOUT=5
export MAX_JOB_TIME=300
python workers/run_deeper_worker.py
```

**Variables:**
- `WORKER_NAME`: Unique identifier for this worker (default: `worker_{pid}`)
- `POLL_TIMEOUT`: Seconds to wait for jobs (default: 5)
- `MAX_JOB_TIME`: Maximum seconds per job (default: 300)

## How It Works

### 1. Job Submission
- Frontend calls `POST /api/deeper-analysis/compute`
- FastAPI creates a job and adds it to Redis queue
- Returns immediately with `job_id`

### 2. Job Processing
- Worker polls Redis queue (blocking pop)
- Picks up job when available
- Computes GOD, ROD, GRPAN for all symbols
- Saves results to Redis

### 3. Status Polling
- Frontend polls `GET /api/deeper-analysis/status/{job_id}`
- Gets status: `queued` ‚Üí `processing` ‚Üí `completed` or `failed`

### 4. Result Retrieval
- When status is `completed`, frontend calls `GET /api/deeper-analysis/result/{job_id}`
- Gets computed results from Redis

## Data Flow

```
Frontend ‚Üí FastAPI ‚Üí Redis Queue
                          ‚Üì
                    Worker Process
                          ‚Üì
                    Redis Results
                          ‚Üì
                    FastAPI ‚Üí Frontend
```

## Monitoring

### Check Worker Status

Worker logs show:
- ‚úÖ Job processing start/completion
- ‚ùå Errors
- üìä Statistics (processed/failed counts)

### Check Redis Queue

```bash
docker exec -it redis-quant-engine redis-cli
> LLEN deeper_analysis:jobs
> KEYS deeper_analysis:*
```

### Check Job Status (via API)

```bash
curl http://localhost:8000/api/deeper-analysis/status/{job_id}
```

## Troubleshooting

### Worker Not Processing Jobs

1. **Check Redis connection:**
   ```bash
   docker ps | grep redis
   ```

2. **Check worker logs:**
   - Look for "‚úÖ Worker connected to Redis"
   - Check for connection errors

3. **Verify queue:**
   ```bash
   docker exec -it redis-quant-engine redis-cli LLEN deeper_analysis:jobs
   ```

### Jobs Stuck in Queue

- Check if workers are running
- Check worker logs for errors
- Restart workers if needed

### Redis Connection Failed

- Ensure Redis Docker container is running:
  ```bash
  docker start redis-quant-engine
  ```
- Check Redis host/port in `settings.py`

## Scaling

### Run Multiple Workers

You can run multiple workers simultaneously for load distribution:

```bash
# Terminal 2
set WORKER_NAME=worker1
python workers\run_deeper_worker.py

# Terminal 3
set WORKER_NAME=worker2
python workers\run_deeper_worker.py

# Terminal 4
set WORKER_NAME=worker3
python workers\run_deeper_worker.py
```

Each worker will:
- Process jobs independently
- Share the same Redis queue
- Distribute load automatically

## Integration with Other Processes

The worker architecture allows other processes to:

1. **Submit jobs** via FastAPI or directly to Redis
2. **Read results** from Redis (any process with Redis access)
3. **Monitor status** via FastAPI endpoints

Example: Another Python script can read results:

```python
import redis
r = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
result = r.get('deeper_analysis:result:{job_id}')
```

## Notes

- ‚ö†Ô∏è **Worker must have access to DataFabric**: Ensure tick-by-tick data is enabled
- ‚ö†Ô∏è **Results expire**: Results stored for 2 hours, status for 1 hour
- ‚ö†Ô∏è **Graceful shutdown**: Workers handle SIGINT/SIGTERM for clean shutdown


